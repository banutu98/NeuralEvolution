{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import gzip\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.special import expit, softmax\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NR_EPOCHS = 200\n",
    "POP_SIZE = 200\n",
    "ELITISM_NR = 10\n",
    "HIGHER_BOUND = 10\n",
    "LOWER_BOUND = -10\n",
    "INTERVALS_NR = (HIGHER_BOUND - LOWER_BOUND) * 10 ** 4\n",
    "BITS_NR = math.ceil(np.log2(INTERVALS_NR))\n",
    "MUTATION_PROB = 0.03\n",
    "CROSSOVER_PROB = 0.6\n",
    "BATCH_SIZE = 256\n",
    "IDXS = 2 ** np.arange(BITS_NR)[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_bits(bits, indices):\n",
    "    return bits.dot(indices)\n",
    "\n",
    "\n",
    "def convert(m):\n",
    "    convert_bits_vect = np.vectorize(convert_bits,\n",
    "                                     otypes=[np.uint32],\n",
    "                                     signature='(m,n),(n)->(m)')\n",
    "    result = convert_bits_vect(m, IDXS) / (2 ** BITS_NR - 1)\n",
    "    return result * (HIGHER_BOUND - LOWER_BOUND) + LOWER_BOUND\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Activation functions\n",
    "# TODO: See which is more efficient\n",
    "def sigmoid(z):\n",
    "    return np.divide(1, (1 + np.exp(-z)))\n",
    "\n",
    "\n",
    "def expit_approx(x):\n",
    "    return 1.0 / (1 + np.abs(x))\n",
    "\n",
    "\n",
    "def softplus(x):\n",
    "    return np.log(1 + np.exp(x))\n",
    "\n",
    "\n",
    "# expit imported from scipy.special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fitness_network(x, y, params, testing=False):\n",
    "    first_layer_weights = params[0]\n",
    "    second_layer_weights = params[1]\n",
    "    third_layer_weights = params[2]\n",
    "    first_layer_biases = params[3]\n",
    "    second_layer_biases = params[4]\n",
    "    third_layer_biases = params[5]\n",
    "    y_pred = list()\n",
    "    for start_idx in range(0, x.shape[0], BATCH_SIZE):\n",
    "        x_batch = x[start_idx:start_idx + BATCH_SIZE]\n",
    "        z1 = np.matmul(x_batch, first_layer_weights) + first_layer_biases\n",
    "        # expit may be better, although it's debatable.\n",
    "        z1 = expit(z1)\n",
    "        z2 = np.matmul(z1, second_layer_weights) + second_layer_biases\n",
    "        z2 = expit(z2)\n",
    "        z3 = np.matmul(z2, third_layer_weights) + third_layer_biases\n",
    "        y3 = softmax(z3)\n",
    "        y_pred.append(y3)\n",
    "    if not testing:\n",
    "        y_pred = np.concatenate(y_pred, axis=1)\n",
    "        y_true = np.broadcast_to(y, (y_pred.shape[0], *y.shape))\n",
    "        return [1 / log_loss(y_true[i], y_pred[i])\n",
    "                for i in range(y_pred.shape[0])]\n",
    "    else:\n",
    "        y_pred = np.concatenate(y_pred)\n",
    "        y_pred = np.apply_along_axis(np.argmax, 1, y_pred)\n",
    "        return np.sum(y_pred == y) / y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def mutate(m):\n",
    "    return np.where(np.random.rand(*m.shape) < MUTATION_PROB,\n",
    "                    1 - m,\n",
    "                    m)\n",
    "\n",
    "\n",
    "def crossover(m, cross_percentages):\n",
    "    def swap_weights(mat, i1, i2):\n",
    "        n_pop = len(i1)\n",
    "        i = np.random.randint(mat.shape[1], size=(n_pop,))\n",
    "        j = np.random.randint(mat.shape[2], size=(n_pop,))\n",
    "        for i1_idx, i2_idx in zip(i1, i2):\n",
    "            temp = mat[i1_idx, i, j].copy()\n",
    "            mat[i1_idx, i, j] = mat[i2_idx, i, j]\n",
    "            mat[i2_idx, i, j] = temp\n",
    "\n",
    "    def swap_neurons(mat, i1, i2):\n",
    "        n_pop = len(i1)\n",
    "        i = np.random.randint(mat.shape[1], size=(n_pop,))\n",
    "        for i1_idx, i2_idx in zip(i1, i2):\n",
    "            temp = mat[i1_idx, i].copy()\n",
    "            mat[i1_idx, i] = mat[i2_idx, i]\n",
    "            mat[i2_idx, i] = temp\n",
    "\n",
    "    def swap_layers(mat, i1, i2):\n",
    "        for i1_idx, i2_idx in zip(i1, i2):\n",
    "            temp = mat[i1_idx].copy()\n",
    "            mat[i1_idx] = mat[i2_idx]\n",
    "            mat[i2_idx] = temp\n",
    "\n",
    "    def split_perc(indices, perc):\n",
    "        # Turn percentages into values between 0 and 1\n",
    "        splits = np.cumsum(perc)\n",
    "        if splits[-1] != 1:\n",
    "            raise ValueError(\"percents don't add up to 100\")\n",
    "        # Split doesn't need last percent, it will just take what is left\n",
    "        splits = splits[:-1]\n",
    "        # Turn values into indices\n",
    "        splits *= len(indices)\n",
    "        # Turn double indices into integers.\n",
    "        # CAUTION: numpy rounds to closest EVEN number when a number is halfway\n",
    "        # between two integers. So 0.5 will become 0 and 1.5 will become 2!\n",
    "        # If you want to round up in all those cases, do\n",
    "        # splits += 0.5 instead of round() before casting to int\n",
    "        splits = splits.round().astype(np.int)\n",
    "        splits = np.split(indices, splits)\n",
    "        # Make arrays of even lengths\n",
    "        for i in range(len(splits)):\n",
    "            if len(splits[i]) % 2:\n",
    "                splits[i] = np.append(splits[i],\n",
    "                                      np.random.choice(splits[i],\n",
    "                                                       size=(1,)))\n",
    "        return splits\n",
    "\n",
    "    # ACTUAL FUNCTION LOGIC STARTS HERE\n",
    "\n",
    "    cross_indices = np.arange(POP_SIZE)[np.random.rand(POP_SIZE) < CROSSOVER_PROB]\n",
    "    shuffled_indices = np.random.choice(cross_indices,\n",
    "                                        size=cross_indices.size,\n",
    "                                        replace=False)\n",
    "    weights, neurons, layers = split_perc(shuffled_indices, cross_percentages)\n",
    "    swap_weights(m, *np.split(weights, 2))\n",
    "    swap_neurons(m, *np.split(neurons, 2))\n",
    "    swap_layers(m, *np.split(layers, 2))\n",
    "\n",
    "\n",
    "def upgrade(population, cross_percentages=(.3, .3, .4)):\n",
    "    new_population = []\n",
    "    for i in range(len(population)):\n",
    "        layer = population[i]\n",
    "        layer_new = mutate(layer)\n",
    "        # This function modifies the matrix in-place\n",
    "        crossover(layer_new, cross_percentages)\n",
    "        new_population.append(layer_new)\n",
    "    return tuple(new_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def selection(population, fitness_values):\n",
    "    new_population = list()\n",
    "    #best_fitness_values = sorted(fitness_values, reverse=True)[:ELITISM_NR]\n",
    "    #chosen_elitism_values = [np.where(fitness_values == i)[0][0] for i in best_fitness_values]\n",
    "    total_fitness = sum(fitness_values)\n",
    "    individual_probabilities = [fitness_val / total_fitness for fitness_val in fitness_values]\n",
    "    cumulative_probabilities = [0]\n",
    "    for i in range(POP_SIZE):\n",
    "        cumulative_probabilities.append(cumulative_probabilities[i] + individual_probabilities[i])\n",
    "    # Do this for each layer.\n",
    "    for layer in population:\n",
    "        new_layer = []\n",
    "        size = 0\n",
    "        while size < POP_SIZE:# - ELITISM_NR:\n",
    "            r = random.uniform(0.0001, 1)\n",
    "            for i in range(POP_SIZE):\n",
    "                if cumulative_probabilities[i] < r <= cumulative_probabilities[i + 1]:\n",
    "                    if size == POP_SIZE:# - ELITISM_NR:\n",
    "                        break\n",
    "                    new_layer.append(layer[i])\n",
    "                    size += 1\n",
    "        #new_layer.extend([layer[i] for i in chosen_elitism_values])\n",
    "        new_population.append(np.array(new_layer))\n",
    "    return new_population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_best_individual(population, fitness_values):\n",
    "    # best_individual = np.zeros(len(population[0]))\n",
    "    local_best = np.argmax(fitness_values)\n",
    "    best = fitness_values[local_best]\n",
    "    # Ugly, but faster than other ways I can think of.\n",
    "    best_individual = (  # weights\n",
    "        population[0][local_best],\n",
    "        population[1][local_best],\n",
    "        population[2][local_best],\n",
    "        # biases\n",
    "        population[3][local_best],\n",
    "        population[4][local_best],\n",
    "        population[5][local_best])\n",
    "    return best, best_individual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_population():\n",
    "    first_layer_weights = np.random.randint(2,\n",
    "                                            size=(POP_SIZE, 784, 100, BITS_NR),\n",
    "                                            dtype=np.uint8)\n",
    "    second_layer_weights = np.random.randint(2,\n",
    "                                             size=(POP_SIZE, 100, 10, BITS_NR),\n",
    "                                             dtype=np.uint8)\n",
    "    third_layer_weights = np.random.randint(2,\n",
    "                                            size=(POP_SIZE, 10, 10, BITS_NR),\n",
    "                                            dtype=np.uint8)\n",
    "    first_layer_biases = np.random.randint(2,\n",
    "                                           size=(POP_SIZE, 100, BITS_NR),\n",
    "                                           dtype=np.uint8)[:, np.newaxis, :, :]\n",
    "    second_layer_biases = np.random.randint(2,\n",
    "                                            size=(POP_SIZE, 10, BITS_NR),\n",
    "                                            dtype=np.uint8)[:, np.newaxis, :, :]\n",
    "    third_layer_biases = np.random.randint(2,\n",
    "                                           size=(POP_SIZE, 10, BITS_NR),\n",
    "                                           dtype=np.uint8)[:, np.newaxis, :, :]\n",
    "    return (first_layer_weights, second_layer_weights,\n",
    "            third_layer_weights, first_layer_biases,\n",
    "            second_layer_biases, third_layer_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_array_to_binary(real_value_array):\n",
    "    binary_value_array = list()\n",
    "    for real_value in real_value_array:\n",
    "        decimal_value = int((real_value - LOWER_BOUND) / (HIGHER_BOUND - LOWER_BOUND) * (2 ** BITS_NR - 1))\n",
    "        binary_value = bin(decimal_value)[2:]\n",
    "        binary_value = '0' * (BITS_NR - len(binary_value)) + binary_value\n",
    "        binary_value_array.extend([np.uint8(b) for b in binary_value])\n",
    "    binary_value_array = np.reshape(binary_value_array, (len(real_value_array), BITS_NR))\n",
    "    return np.array(binary_value_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_smart_population(x_train, y_train, load=False):\n",
    "    if not load:\n",
    "        input_layer = Input(shape=(784,))\n",
    "        dense_1 = Dense(100, activation='sigmoid')(input_layer)\n",
    "        dense_2 = Dense(10, activation='sigmoid')(dense_1)\n",
    "        pred = Dense(10, activation='softmax')(dense_2)\n",
    "        model = Model(inputs=input_layer, outputs=pred)\n",
    "        model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['acc'])\n",
    "        model.summary()\n",
    "        model.fit(x_train, to_categorical(y_train, num_classes=10), batch_size=256, epochs=1)\n",
    "        model.save('model.h5')\n",
    "        loss, acc = model.evaluate(x_train, to_categorical(y_train))\n",
    "    else:\n",
    "        model = load_model('model.h5')\n",
    "        loss, acc = model.evaluate(x_train, to_categorical(y_train))\n",
    "    print(f'Accuracy from the initial model: {acc}')\n",
    "\n",
    "    first_layer_weights = model.layers[1].get_weights()[0]\n",
    "    first_layer_biases = model.layers[1].get_weights()[1]\n",
    "    second_layer_weights = model.layers[2].get_weights()[0]\n",
    "    second_layer_biases = model.layers[2].get_weights()[1]\n",
    "    third_layer_weights = model.layers[3].get_weights()[0]\n",
    "    third_layer_biases = model.layers[3].get_weights()[1]\n",
    "\n",
    "    first_layer_weights = np.array([convert_array_to_binary(real_array) for real_array in first_layer_weights])\n",
    "    second_layer_weights = np.array([convert_array_to_binary(real_array) for real_array in second_layer_weights])\n",
    "    third_layer_weights = np.array([convert_array_to_binary(real_array) for real_array in third_layer_weights])\n",
    "    first_layer_biases = convert_array_to_binary(first_layer_biases)\n",
    "    second_layer_biases = convert_array_to_binary(second_layer_biases)\n",
    "    third_layer_biases = convert_array_to_binary(third_layer_biases)\n",
    "\n",
    "    first_layer_weights = np.repeat(first_layer_weights[np.newaxis, :], POP_SIZE, axis=0)\n",
    "    second_layer_weights = np.repeat(second_layer_weights[np.newaxis, :], POP_SIZE, axis=0)\n",
    "    third_layer_weights = np.repeat(third_layer_weights[np.newaxis, :], POP_SIZE, axis=0)\n",
    "    first_layer_biases = np.repeat(first_layer_biases[np.newaxis, :], POP_SIZE, axis=0)[:, np.newaxis, :, :]\n",
    "    second_layer_biases = np.repeat(second_layer_biases[np.newaxis, :], POP_SIZE, axis=0)[:, np.newaxis, :, :]\n",
    "    third_layer_biases = np.repeat(third_layer_biases[np.newaxis, :], POP_SIZE, axis=0)[:, np.newaxis, :, :]\n",
    "    return (first_layer_weights, second_layer_weights,\n",
    "            third_layer_weights, first_layer_biases,\n",
    "            second_layer_biases, third_layer_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_population(population):\n",
    "    return tuple(convert(layer)\n",
    "                 for layer in population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def main(use_back_prop=False, load=False):\n",
    "    start_time = time.time()\n",
    "    with gzip.open('mnist.pkl.gz', 'rb') as f:\n",
    "        train_set, _, test_set = pickle.load(f, encoding='latin1')\n",
    "        x_train, y_train = train_set\n",
    "        x_test, y_test = test_set\n",
    "    # best = 0\n",
    "    if load:\n",
    "        if os.path.exists('population.pkl'):\n",
    "            with open('population.pkl', 'rb') as f:\n",
    "                population = pickle.load(f)\n",
    "        else:\n",
    "            if not use_back_prop:\n",
    "                population = generate_population()\n",
    "            else:\n",
    "                population = generate_smart_population(x_train, y_train, load=True)\n",
    "    else:\n",
    "        if not use_back_prop:\n",
    "            population = generate_population()\n",
    "        else:\n",
    "            population = generate_smart_population(x_train, y_train, load=True)\n",
    "\n",
    "    fitness_values = fitness_network(x_train, y_train, convert_population(population))\n",
    "    best, best_individual = get_best_individual(population, fitness_values)\n",
    "    for i in range(NR_EPOCHS):\n",
    "        if i % 10 == 0:\n",
    "            with open('population.pkl', 'wb') as f:\n",
    "                pickle.dump(population, f)\n",
    "        print(f'Current epoch: {i}')\n",
    "        population = selection(population, fitness_values)\n",
    "        population = upgrade(population, cross_percentages=[.3, .3, .4])\n",
    "        fitness_values = fitness_network(x_train, y_train, convert_population(population))\n",
    "        new_best, new_best_individual = get_best_individual(population, fitness_values)\n",
    "        if new_best > best:\n",
    "            best = new_best\n",
    "            # best_individual = np.copy(temp_individual)\n",
    "            best_individual = new_best_individual\n",
    "        best_score = fitness_network(x_train, y_train, convert_population(best_individual), testing=True)\n",
    "        print(f'The network achieved an accuracy of {best_score * 100} percent on training set!')\n",
    "    best_score = fitness_network(x_test, y_test, convert_population(best_individual), testing=True)\n",
    "    print(f'The network achieved an accuracy of {best_score * 100} percent on testing set!')\n",
    "    print(f'Time taken: {time.time() - start_time} seconds!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch: 0\n",
      "The network achieved an accuracy of 10.388 percent on training set!\n",
      "Current epoch: 1\n",
      "The network achieved an accuracy of 10.388 percent on training set!\n",
      "Current epoch: 2\n",
      "The network achieved an accuracy of 10.388 percent on training set!\n",
      "Current epoch: 3\n",
      "The network achieved an accuracy of 10.388 percent on training set!\n",
      "Current epoch: 4\n",
      "The network achieved an accuracy of 10.388 percent on training set!\n",
      "Current epoch: 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c5747f6f402f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_back_prop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-ea86716134b7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(use_back_prop, load)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitness_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupgrade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_percentages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mfitness_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitness_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_population\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mnew_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_best_individual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_best_individual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitness_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_best\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-1100bb8bfa65>\u001b[0m in \u001b[0;36mfitness_network\u001b[0;34m(x, y, params, testing)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         return [1 / log_loss(y_true[i], y_pred[i])\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(use_back_prop=True, load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import gzip\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.special import expit, softmax\n",
    "from scipy.linalg.blas import sgemm\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NR_EPOCHS = 200\n",
    "POP_SIZE = 100\n",
    "ELITISM_NR = 10\n",
    "HIGHER_BOUND = 1\n",
    "LOWER_BOUND = -1\n",
    "INTERVALS_NR = (HIGHER_BOUND - LOWER_BOUND) * 10 ** 4\n",
    "BITS_NR = math.ceil(np.log2(INTERVALS_NR))\n",
    "MUTATION_PROB = 0.1\n",
    "CROSSOVER_PROB = 0.6\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation functions\n",
    "# TODO: See which is more efficient\n",
    "def sigmoid(z):\n",
    "    return np.divide(1, (1 + np.exp(-z)))\n",
    "\n",
    "\n",
    "def expit_approx(x):\n",
    "    return 1.0 / (1 + np.abs(x))\n",
    "\n",
    "\n",
    "def softplus(x):\n",
    "    return np.log(1 + np.exp(x))\n",
    "\n",
    "\n",
    "# expit imported from scipy.special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_network(population, x, y):\n",
    "    losses = []\n",
    "    for individual in population:\n",
    "        first_layer_weights = individual[0]\n",
    "        second_layer_weights = individual[1]\n",
    "        third_layer_weights = individual[2]\n",
    "        first_layer_biases = individual[3]\n",
    "        second_layer_biases = individual[4]\n",
    "        third_layer_biases = individual[5]\n",
    "        y_pred = list()\n",
    "        for start_idx in range(0, x.shape[0], BATCH_SIZE):\n",
    "            x_batch = x[start_idx:start_idx + BATCH_SIZE]\n",
    "            z1 = np.dot(x_batch, first_layer_weights) + first_layer_biases\n",
    "            # expit may be better, although it's debatable.\n",
    "            z1 = expit(z1)\n",
    "            z2 = np.dot(z1, second_layer_weights) + second_layer_biases\n",
    "            z2 = expit(z2)\n",
    "            z3 = np.dot(z2, third_layer_weights) + third_layer_biases\n",
    "            y3 = softmax(z3)\n",
    "            y_pred.append(y3)\n",
    "        y_pred = np.concatenate(y_pred)\n",
    "        losses.append(1/np.exp(log_loss(y, y_pred)))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_network(individual, x, y):\n",
    "    first_layer_weights = individual[0]\n",
    "    second_layer_weights = individual[1]\n",
    "    third_layer_weights = individual[2]\n",
    "    first_layer_biases = individual[3]\n",
    "    second_layer_biases = individual[4]\n",
    "    third_layer_biases = individual[5]\n",
    "    y_pred = list()\n",
    "    for start_idx in range(0, x.shape[0], BATCH_SIZE):\n",
    "        x_batch = x[start_idx:start_idx + BATCH_SIZE]\n",
    "        z1 = np.dot(x_batch, first_layer_weights) + first_layer_biases\n",
    "        # expit may be better, although it's debatable.\n",
    "        z1 = expit(z1)\n",
    "        z2 = np.dot(z1, second_layer_weights) + second_layer_biases\n",
    "        z2 = expit(z2)\n",
    "        z3 = np.dot(z2, third_layer_weights) + third_layer_biases\n",
    "        y3 = softmax(z3)\n",
    "        y_pred.append(y3)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    y_pred = np.apply_along_axis(np.argmax, 1, y_pred)\n",
    "    return np.sum(y_pred == y) / y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(pop):\n",
    "    new_pop = []\n",
    "    for indiv in pop:\n",
    "        new_indiv = []\n",
    "        for layer in indiv:\n",
    "            new_indiv.append(np.where(np.random.rand(*layer.shape) < MUTATION_PROB,\n",
    "                                      np.random.uniform(low=LOWER_BOUND,\n",
    "                                                        high=HIGHER_BOUND,\n",
    "                                                        size=layer.shape),\n",
    "                                      layer))\n",
    "        new_pop.append(new_indiv)\n",
    "    return new_pop\n",
    "\n",
    "\n",
    "def crossover(pop, cross_percentages):\n",
    "    def swap_weights(p, i1, i2):\n",
    "        for i1_idx, i2_idx in zip(i1, i2):\n",
    "            # choose a random layer (weights only)\n",
    "            l = random.randint(0, 2)\n",
    "            i = random.randint(0, p[i1_idx][l].shape[0]-1)\n",
    "            j = random.randint(0, p[i1_idx][l].shape[1]-1)\n",
    "            temp = p[i1_idx][l][i, j].copy()\n",
    "            p[i1_idx][l][i, j] = p[i2_idx][l][i, j]\n",
    "            p[i2_idx][l][i, j] = temp\n",
    "\n",
    "    def swap_neurons(p, i1, i2):\n",
    "        for i1_idx, i2_idx in zip(i1, i2):\n",
    "            # choose a random layer (weights and biases)\n",
    "            l = random.randint(0, 5)\n",
    "            i = random.randint(0, p[i1_idx][l].shape[0]-1)\n",
    "            temp = p[i1_idx][l][i].copy()\n",
    "            p[i1_idx][l][i] = p[i2_idx][l][i]\n",
    "            p[i2_idx][l][i] = temp\n",
    "\n",
    "    def swap_layers(p, i1, i2):\n",
    "        for i1_idx, i2_idx in zip(i1, i2):\n",
    "            # choose a random layer (weights and biases)\n",
    "            l = random.randint(0, 5)\n",
    "            temp = p[i1_idx][l].copy()\n",
    "            p[i1_idx][l] = p[i2_idx][l]\n",
    "            p[i2_idx][l] = temp\n",
    "\n",
    "    def split_perc(indices, perc):\n",
    "        # Turn percentages into values between 0 and 1\n",
    "        splits = np.cumsum(perc)\n",
    "        if splits[-1] != 1:\n",
    "            raise ValueError(\"percents don't add up to 100\")\n",
    "        # Split doesn't need last percent, it will just take what is left\n",
    "        splits = splits[:-1]\n",
    "        # Turn values into indices\n",
    "        splits *= len(indices)\n",
    "        # Turn double indices into integers.\n",
    "        # CAUTION: numpy rounds to closest EVEN number when a number is halfway\n",
    "        # between two integers. So 0.5 will become 0 and 1.5 will become 2!\n",
    "        # If you want to round up in all those cases, do\n",
    "        # splits += 0.5 instead of round() before casting to int\n",
    "        splits = splits.round().astype(np.int)\n",
    "        splits = np.split(indices, splits)\n",
    "        # Make arrays of even lengths\n",
    "        for i in range(len(splits)):\n",
    "            if len(splits[i]) % 2:\n",
    "                splits[i] = np.append(splits[i],\n",
    "                                      np.random.choice(splits[i],\n",
    "                                                       size=(1,)))\n",
    "        return splits\n",
    "\n",
    "    # ACTUAL FUNCTION LOGIC STARTS HERE\n",
    "\n",
    "    cross_indices = np.arange(POP_SIZE)[np.random.rand(POP_SIZE) < CROSSOVER_PROB]\n",
    "    shuffled_indices = np.random.choice(cross_indices,\n",
    "                                        size=cross_indices.size,\n",
    "                                        replace=False)\n",
    "    weights, neurons, layers = split_perc(shuffled_indices, cross_percentages)\n",
    "    swap_weights(pop, *np.split(weights, 2))\n",
    "    swap_neurons(pop, *np.split(neurons, 2))\n",
    "    swap_layers(pop, *np.split(layers, 2))\n",
    "\n",
    "\n",
    "def upgrade(population, cross_percentages=(.3, .3, .4)):\n",
    "    new_population = mutate(population)\n",
    "    # This function modifies the matrix in-place\n",
    "    crossover(new_population, cross_percentages)\n",
    "    return new_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection(population, fitness_values):\n",
    "    new_population = []\n",
    "    #best_fitness_values = sorted(fitness_values, reverse=True)[:ELITISM_NR]\n",
    "    #chosen_elitism_values = [np.where(fitness_values == i)[0][0] for i in best_fitness_values]\n",
    "    # Compute cumulative distribution.\n",
    "    total_fitness = sum(fitness_values)\n",
    "    individual_probabilities = [fitness_val / total_fitness for fitness_val in fitness_values]\n",
    "    cummulative_probabilities = np.cumsum(individual_probabilities)\n",
    "    # Generate probabilities for new population.\n",
    "    r = np.random.rand(POP_SIZE)\n",
    "    # Get insertion points through a left bisect algorithm.\n",
    "    selected = np.searchsorted(cummulative_probabilities, r)\n",
    "    for idx in selected:\n",
    "        new_population.append(population[idx])\n",
    "    return new_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_individual(population, fitness_values):\n",
    "    local_best = np.argmax(fitness_values)\n",
    "    best = fitness_values[local_best]\n",
    "    best_individual = population[local_best]\n",
    "    return best, best_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_population():\n",
    "    return [[np.random.uniform(low=LOWER_BOUND,\n",
    "                               high=HIGHER_BOUND,\n",
    "                               size=(784, 100)).astype('f'),\n",
    "             np.random.uniform(low=LOWER_BOUND,\n",
    "                               high=HIGHER_BOUND,\n",
    "                               size=(100, 10)).astype('f'),\n",
    "             np.random.uniform(low=LOWER_BOUND,\n",
    "                               high=HIGHER_BOUND,\n",
    "                               size=(10, 10)).astype('f'),\n",
    "             np.random.uniform(low=LOWER_BOUND,\n",
    "                               high=HIGHER_BOUND,\n",
    "                               size=(100,)).astype('f'),\n",
    "             np.random.uniform(low=LOWER_BOUND,\n",
    "                               high=HIGHER_BOUND,\n",
    "                               size=(10,)).astype('f'),\n",
    "             np.random.uniform(low=LOWER_BOUND,\n",
    "                               high=HIGHER_BOUND,\n",
    "                               size=(10,)).astype('f')]\n",
    "            for _ in range(POP_SIZE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    start_time = time.time()\n",
    "    with gzip.open('mnist.pkl.gz', 'rb') as f:\n",
    "        train_set, _, test_set = pickle.load(f, encoding='latin1')\n",
    "        x_train, y_train = train_set\n",
    "        x_test, y_test = test_set\n",
    "    population = generate_population()\n",
    "    print(population[0][0].shape[0])\n",
    "    fitness_values = fitness_network(population, x_train, y_train)\n",
    "    best, best_individual = get_best_individual(population, fitness_values)\n",
    "    for i in range(NR_EPOCHS):\n",
    "        print(f'Current epoch: {i}')\n",
    "        old_population = population\n",
    "        population = selection(population, fitness_values)\n",
    "        population = upgrade(population, cross_percentages=[.40, .55, .05])\n",
    "        #print('populations equal?')\n",
    "        old_fitness_values = fitness_values\n",
    "        fitness_values = fitness_network(population, x_train, y_train)\n",
    "        print('fitness equal?',\n",
    "              np.allclose(fitness_values,old_fitness_values))\n",
    "        new_best, new_best_individual = get_best_individual(population, fitness_values)\n",
    "        print('current best:', best)\n",
    "        print('new best:', new_best)\n",
    "        if new_best > best:\n",
    "            best = new_best\n",
    "            best_individual = new_best_individual\n",
    "            best_score = test_network(best_individual, x_train, y_train)\n",
    "            print(f'The network achieved an accuracy of {best_score * 100} percent on training set!')\n",
    "    best_score = test_network(best_individual, x_test, y_test)\n",
    "    print(f'The network achieved an accuracy of {best_score * 100} percent on testing set!')\n",
    "    print(f'Time taken: {time.time() - start_time} seconds!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "Current epoch: 0\n",
      "fitness equal? False\n",
      "current best: 0.07942927141727997\n",
      "new best: 0.07965937396028541\n",
      "The network achieved an accuracy of 9.698 percent on training set!\n",
      "Current epoch: 1\n",
      "fitness equal? False\n",
      "current best: 0.07965937396028541\n",
      "new best: 0.08157136300651106\n",
      "The network achieved an accuracy of 8.334 percent on training set!\n",
      "Current epoch: 2\n",
      "fitness equal? False\n",
      "current best: 0.08157136300651106\n",
      "new best: 0.0895992351248829\n",
      "The network achieved an accuracy of 12.91 percent on training set!\n",
      "Current epoch: 3\n",
      "fitness equal? False\n",
      "current best: 0.0895992351248829\n",
      "new best: 0.08130523801370933\n",
      "Current epoch: 4\n",
      "fitness equal? False\n",
      "current best: 0.0895992351248829\n",
      "new best: 0.08860029259083997\n",
      "Current epoch: 5\n",
      "fitness equal? False\n",
      "current best: 0.0895992351248829\n",
      "new best: 0.0809285087704987\n",
      "Current epoch: 6\n",
      "fitness equal? False\n",
      "current best: 0.0895992351248829\n",
      "new best: 0.08531122774157743\n",
      "Current epoch: 7\n",
      "fitness equal? False\n",
      "current best: 0.0895992351248829\n",
      "new best: 0.08186431682935438\n",
      "Current epoch: 8\n",
      "fitness equal? False\n",
      "current best: 0.0895992351248829\n",
      "new best: 0.08482556669900428\n",
      "Current epoch: 9\n",
      "fitness equal? False\n",
      "current best: 0.0895992351248829\n",
      "new best: 0.08278410900993849\n",
      "Current epoch: 10\n",
      "fitness equal? False\n",
      "current best: 0.0895992351248829\n",
      "new best: 0.08574459033762434\n",
      "Current epoch: 11\n",
      "fitness equal? False\n",
      "current best: 0.0895992351248829\n",
      "new best: 0.08923458445747624\n",
      "Current epoch: 12\n",
      "fitness equal? False\n",
      "current best: 0.0895992351248829\n",
      "new best: 0.08447111384927464\n",
      "Current epoch: 13\n",
      "fitness equal? False\n",
      "current best: 0.0895992351248829\n",
      "new best: 0.08347845014626196\n",
      "Current epoch: 14\n",
      "fitness equal? False\n",
      "current best: 0.0895992351248829\n",
      "new best: 0.08957463821964518\n",
      "Current epoch: 15\n",
      "fitness equal? False\n",
      "current best: 0.0895992351248829\n",
      "new best: 0.0831443845655255\n",
      "Current epoch: 16\n",
      "fitness equal? False\n",
      "current best: 0.0895992351248829\n",
      "new best: 0.0820666660401974\n",
      "Current epoch: 17\n",
      "fitness equal? False\n",
      "current best: 0.0895992351248829\n",
      "new best: 0.08376118810530779\n",
      "Current epoch: 18\n",
      "fitness equal? False\n",
      "current best: 0.0895992351248829\n",
      "new best: 0.08590119329135706\n",
      "Current epoch: 19\n",
      "fitness equal? False\n",
      "current best: 0.0895992351248829\n",
      "new best: 0.09251542812943024\n",
      "The network achieved an accuracy of 15.006 percent on training set!\n",
      "Current epoch: 20\n",
      "fitness equal? False\n",
      "current best: 0.09251542812943024\n",
      "new best: 0.08722563155995693\n",
      "Current epoch: 21\n",
      "fitness equal? False\n",
      "current best: 0.09251542812943024\n",
      "new best: 0.09316421591171148\n",
      "The network achieved an accuracy of 13.081999999999999 percent on training set!\n",
      "Current epoch: 22\n",
      "fitness equal? False\n",
      "current best: 0.09316421591171148\n",
      "new best: 0.08897811211081269\n",
      "Current epoch: 23\n",
      "fitness equal? False\n",
      "current best: 0.09316421591171148\n",
      "new best: 0.0902962544890239\n",
      "Current epoch: 24\n",
      "fitness equal? False\n",
      "current best: 0.09316421591171148\n",
      "new best: 0.09163481129908421\n",
      "Current epoch: 25\n",
      "fitness equal? False\n",
      "current best: 0.09316421591171148\n",
      "new best: 0.09486272722350476\n",
      "The network achieved an accuracy of 8.424 percent on training set!\n",
      "Current epoch: 26\n",
      "fitness equal? False\n",
      "current best: 0.09486272722350476\n",
      "new best: 0.09045887148660499\n",
      "Current epoch: 27\n",
      "fitness equal? False\n",
      "current best: 0.09486272722350476\n",
      "new best: 0.09830327582124888\n",
      "The network achieved an accuracy of 13.194 percent on training set!\n",
      "Current epoch: 28\n",
      "fitness equal? False\n",
      "current best: 0.09830327582124888\n",
      "new best: 0.08847973952704938\n",
      "Current epoch: 29\n",
      "fitness equal? False\n",
      "current best: 0.09830327582124888\n",
      "new best: 0.08924378427986024\n",
      "Current epoch: 30\n",
      "fitness equal? False\n",
      "current best: 0.09830327582124888\n",
      "new best: 0.08838207322762165\n",
      "Current epoch: 31\n",
      "fitness equal? False\n",
      "current best: 0.09830327582124888\n",
      "new best: 0.09245060868708989\n",
      "Current epoch: 32\n",
      "fitness equal? False\n",
      "current best: 0.09830327582124888\n",
      "new best: 0.08969426965737443\n",
      "Current epoch: 33\n",
      "fitness equal? False\n",
      "current best: 0.09830327582124888\n",
      "new best: 0.08871019076045149\n",
      "Current epoch: 34\n",
      "fitness equal? False\n",
      "current best: 0.09830327582124888\n",
      "new best: 0.08775227261864141\n",
      "Current epoch: 35\n",
      "fitness equal? False\n",
      "current best: 0.09830327582124888\n",
      "new best: 0.086985114975043\n",
      "Current epoch: 36\n",
      "fitness equal? False\n",
      "current best: 0.09830327582124888\n",
      "new best: 0.09073184498078503\n",
      "Current epoch: 37\n",
      "fitness equal? False\n",
      "current best: 0.09830327582124888\n",
      "new best: 0.09445230565024529\n",
      "Current epoch: 38\n",
      "fitness equal? False\n",
      "current best: 0.09830327582124888\n",
      "new best: 0.093010674098132\n",
      "Current epoch: 39\n",
      "fitness equal? False\n",
      "current best: 0.09830327582124888\n",
      "new best: 0.099711867146157\n",
      "The network achieved an accuracy of 12.652 percent on training set!\n",
      "Current epoch: 40\n",
      "fitness equal? False\n",
      "current best: 0.099711867146157\n",
      "new best: 0.08727562819081738\n",
      "Current epoch: 41\n",
      "fitness equal? False\n",
      "current best: 0.099711867146157\n",
      "new best: 0.08725824077342066\n",
      "Current epoch: 42\n",
      "fitness equal? False\n",
      "current best: 0.099711867146157\n",
      "new best: 0.09033298289916501\n",
      "Current epoch: 43\n",
      "fitness equal? False\n",
      "current best: 0.099711867146157\n",
      "new best: 0.0985794658718069\n",
      "Current epoch: 44\n",
      "fitness equal? False\n",
      "current best: 0.099711867146157\n",
      "new best: 0.08953309210336452\n",
      "Current epoch: 45\n",
      "fitness equal? False\n",
      "current best: 0.099711867146157\n",
      "new best: 0.09538476922868672\n",
      "Current epoch: 46\n",
      "fitness equal? False\n",
      "current best: 0.099711867146157\n",
      "new best: 0.09532786124149492\n",
      "Current epoch: 47\n",
      "fitness equal? False\n",
      "current best: 0.099711867146157\n",
      "new best: 0.09620418164405298\n",
      "Current epoch: 48\n",
      "fitness equal? False\n",
      "current best: 0.099711867146157\n",
      "new best: 0.09157199879563095\n",
      "Current epoch: 49\n",
      "fitness equal? False\n",
      "current best: 0.099711867146157\n",
      "new best: 0.08566588312002334\n",
      "Current epoch: 50\n",
      "fitness equal? False\n",
      "current best: 0.099711867146157\n",
      "new best: 0.08868487929119781\n",
      "Current epoch: 51\n",
      "fitness equal? False\n",
      "current best: 0.099711867146157\n",
      "new best: 0.08716533950912282\n",
      "Current epoch: 52\n",
      "fitness equal? False\n",
      "current best: 0.099711867146157\n",
      "new best: 0.09239617122317861\n",
      "Current epoch: 53\n",
      "fitness equal? False\n",
      "current best: 0.099711867146157\n",
      "new best: 0.0893002017416584\n",
      "Current epoch: 54\n",
      "fitness equal? False\n",
      "current best: 0.099711867146157\n",
      "new best: 0.09077736257188038\n",
      "Current epoch: 55\n",
      "fitness equal? False\n",
      "current best: 0.099711867146157\n",
      "new best: 0.0898752594257714\n",
      "Current epoch: 56\n",
      "fitness equal? False\n",
      "current best: 0.099711867146157\n",
      "new best: 0.0822549724300565\n",
      "Current epoch: 57\n",
      "fitness equal? False\n",
      "current best: 0.099711867146157\n",
      "new best: 0.08522308162447131\n",
      "Current epoch: 58\n",
      "fitness equal? False\n",
      "current best: 0.099711867146157\n",
      "new best: 0.09010478037104543\n",
      "Current epoch: 59\n",
      "fitness equal? False\n",
      "current best: 0.099711867146157\n",
      "new best: 0.08801498595183922\n",
      "Current epoch: 60\n",
      "fitness equal? False\n",
      "current best: 0.099711867146157\n",
      "new best: 0.09430261398702762\n",
      "Current epoch: 61\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c7bc734e5e35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-de795e961f0f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#print('populations equal?')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mold_fitness_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitness_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mfitness_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitness_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         print('fitness equal?',\n\u001b[1;32m     20\u001b[0m               np.allclose(fitness_values,old_fitness_values))\n",
      "\u001b[0;32m<ipython-input-4-7eaf7db9f416>\u001b[0m in \u001b[0;36mfitness_network\u001b[0;34m(population, x, y)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstart_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstart_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_layer_weights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfirst_layer_biases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;31m# expit may be better, although it's debatable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('mnist.pkl.gz', 'rb') as f:\n",
    "        train_set, _, test_set = pickle.load(f, encoding='latin1')\n",
    "        x_train, y_train = train_set\n",
    "        x_test, y_test = test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = (np.random.rand(POP_SIZE, 784, 100).astype('f'),\n",
    "         np.random.rand(POP_SIZE, 100, 10).astype('f'),\n",
    "         np.random.rand(POP_SIZE, 10, 10).astype('f'),\n",
    "         np.random.rand(POP_SIZE, 100).astype('f')[:, np.newaxis, :],\n",
    "         np.random.rand(POP_SIZE, 10).astype('f')[:, np.newaxis, :],\n",
    "         np.random.rand(POP_SIZE, 10).astype('f')[:, np.newaxis, :])\n",
    "\n",
    "individuals = [[np.random.rand(784, 100).astype('f'),\n",
    "                np.random.rand(100, 10).astype('f'),\n",
    "                np.random.rand(10, 10).astype('f'),\n",
    "                np.random.rand(100).astype('f'),\n",
    "                np.random.rand(10).astype('f'),\n",
    "                np.random.rand(10).astype('f')] for _ in range(POP_SIZE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ff_group(population, x, y):\n",
    "    first_layer_weights = population[0]\n",
    "    second_layer_weights = population[1]\n",
    "    third_layer_weights = population[2]\n",
    "    first_layer_biases = population[3]\n",
    "    second_layer_biases = population[4]\n",
    "    third_layer_biases = population[5]\n",
    "    y_pred = list()\n",
    "    for start_idx in range(0, x.shape[0], BATCH_SIZE):\n",
    "        x_batch = x[start_idx:start_idx + BATCH_SIZE]\n",
    "        z1 = np.matmul(x_batch, first_layer_weights) + first_layer_biases\n",
    "        # expit may be better, although it's debatable.\n",
    "        z1 = expit(z1)\n",
    "        z2 = np.matmul(z1, second_layer_weights) + second_layer_biases\n",
    "        z2 = expit(z2)\n",
    "        z3 = np.matmul(z2, third_layer_weights) + third_layer_biases\n",
    "        y3 = softmax(z3)\n",
    "        y_pred.append(y3)\n",
    "    y_pred = np.concatenate(y_pred, axis=1)\n",
    "    y_true = np.broadcast_to(y, (y_pred.shape[0], *y.shape))\n",
    "    return [log_loss(y_true[i], y_pred[i])\n",
    "            for i in range(y_pred.shape[0])]\n",
    "    \n",
    "def test_ff_iterate(population, x, y):\n",
    "    losses = []\n",
    "    for individual in population:\n",
    "        first_layer_weights = individual[0]\n",
    "        second_layer_weights = individual[1]\n",
    "        third_layer_weights = individual[2]\n",
    "        first_layer_biases = individual[3]\n",
    "        second_layer_biases = individual[4]\n",
    "        third_layer_biases = individual[5]\n",
    "        y_pred = list()\n",
    "        for start_idx in range(0, x.shape[0], BATCH_SIZE):\n",
    "            x_batch = x[start_idx:start_idx + BATCH_SIZE]\n",
    "            z1 = np.dot(x_batch, first_layer_weights) + first_layer_biases\n",
    "            # expit may be better, although it's debatable.\n",
    "            z1 = expit(z1)\n",
    "            z2 = np.dot(z1, second_layer_weights) + second_layer_biases\n",
    "            z2 = expit(z2)\n",
    "            z3 = np.dot(z2, third_layer_weights) + third_layer_biases\n",
    "            y3 = softmax(z3)\n",
    "            y_pred.append(y3)\n",
    "        y_pred = np.concatenate(y_pred)\n",
    "        losses.append(log_loss(y, y_pred))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-7fc56208ac87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test_ff_group(group, x_train, y_train)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/envs/mlenv/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2315\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/klaus/.pyenv/versions/3.7.5/envs/mlenv/lib/python3.7/site-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/envs/mlenv/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/envs/mlenv/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/envs/mlenv/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;32m<ipython-input-86-73372f84048c>\u001b[0m in \u001b[0;36mtest_ff_group\u001b[0;34m(population, x, y)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstart_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstart_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_layer_weights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfirst_layer_biases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m# expit may be better, although it's debatable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%timeit test_ff_group(group, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ff_iterate(individuals, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit test_ff_iterate(individuals, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "for l in group:\n",
    "    mutate(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "for i in individuals:\n",
    "    for l in i:\n",
    "        mutate(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness = test_ff_iterate(individuals, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit selection(individuals, fitness)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
